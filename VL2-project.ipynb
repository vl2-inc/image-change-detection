{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ5OIYJv8plu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvtDIWED8vKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "#import keras \n",
        "from keras import optimizers\n",
        "from keras.applications.vgg19 import VGG19\n",
        "#from keras.applications.vgg19 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "#import numpy as np\n",
        "from keras.models import Model \n",
        "from keras.layers import Input , Convolution2D , Conv2DTranspose , Reshape\n",
        "from keras.layers import concatenate\n",
        "#from keras import backend as K\n",
        "\n",
        "#input_img1 = Input((224,224,3))\n",
        "#input_img2 = Input((224,224,3))\n",
        "\n",
        "model1 = VGG19(weights = \"imagenet\", include_top=False,input_shape=(224,224,3))\n",
        "model2 = VGG19(weights = \"imagenet\", include_top=False,input_shape=(224,224,3))\n",
        "\n",
        "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
        "for layer in model1.layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "for layer in model2.layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "for layer in model2.layers:\n",
        "    layer.name = layer.name + str(\"_2\")\n",
        "\n",
        "#Adding custom Layers \n",
        "x1 = model1.output\n",
        "x2 = model2.output\n",
        "\n",
        "# combine the output of the two branches\n",
        "x = concatenate([x1, x2])\n",
        "\n",
        "x = Convolution2D(1,(1,1), padding =\"same\", activation='relu')(x)\n",
        "\n",
        "x = Conv2DTranspose(1,(1,1), strides=(16,16) , padding =\"same\" , activation='softmax')(x)\n",
        "\n",
        "prediction = Reshape((112,112))(x)\n",
        "# creating the final model \n",
        "VL2_model = Model(input = [model1.input , model2.input], output = prediction)\n",
        "\n",
        "print(VL2_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HTwYTGD82s5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import os\n",
        "#import keras \n",
        "from keras import optimizers\n",
        "from keras.applications.vgg19 import VGG19\n",
        "#from keras.applications.vgg19 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.models import Model \n",
        "from keras.layers import Flatten , Dense , Dropout , concatenate\n",
        "#from keras import backend as K\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_train01 = '/content/drive/My Drive/Fake/Train/Input01'\n",
        "input_train02 = '/content/drive/My Drive/Fake/Train/Input02'\n",
        "output_train = '/content/drive/My Drive/Fake/Train/Output'\n",
        "\n",
        "input_test01 = '/content/drive/My Drive/Fake/Test/Input01'\n",
        "input_test02 = '/content/drive/My Drive/Fake/Test/Input02'\n",
        "output_test = '/content/drive/My Drive/Fake/Test/Output'\n",
        "\n",
        "##Preparamos nuestras imagenes\n",
        "\n",
        "def data_gen(path,i):\n",
        "  datagen = []\n",
        "  if i==0:\n",
        "    for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "      img_array = cv2.imread(os.path.join(path,img))  # convert to array #,cv2.IMREAD_GRAYSCALE\n",
        "      datagen.append(img_array)  # add this to our training_data\n",
        "  if i==1:\n",
        "    for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "      img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array #,cv2.IMREAD_GRAYSCALE\n",
        "      datagen.append(img_array)  # add this to our training_data\n",
        "  return datagen\n",
        "\n",
        "input_train01 = np.array(data_gen(input_train01,0))\n",
        "input_train02 = np.array(data_gen(input_train02,0))\n",
        "output_train = np.array(data_gen(output_train,1))\n",
        "\n",
        "input_test01 = np.array(data_gen(input_test01,0))\n",
        "input_test02 = np.array(data_gen(input_test02,0))\n",
        "output_test = np.array(data_gen(output_test,1))\n",
        "\n",
        "#RED NEURONAL\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "model1 = VGG19(weights = \"imagenet\", include_top=False,input_shape=(224,224,3))\n",
        "model2 = VGG19(weights = \"imagenet\", include_top=False,input_shape=(224,224,3))\n",
        "\n",
        "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
        "for layer in model1.layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "for layer in model2.layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "for layer in model2.layers:\n",
        "    layer.name = layer.name + str(\"_2\")\n",
        "\n",
        "#Adding custom Layers \n",
        "x1 = model1.output\n",
        "x2 = model2.output\n",
        "\n",
        "# combine the output of the two branches\n",
        "x = concatenate([x1, x2])\n",
        "\n",
        "x = Convolution2D(1,(1,1), padding =\"same\", activation='relu')(x)\n",
        "\n",
        "x = Conv2DTranspose(1,(1,1), strides=(16,16) , padding =\"same\" , activation='softmax')(x)\n",
        "\n",
        "prediction = Reshape((112,112))(x)\n",
        "\n",
        "# creating the final model \n",
        "VL2_model = Model(input = [model1.input , model2.input], output = prediction)\n",
        "  \n",
        "VL2_model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.0005),metrics=['accuracy'])\n",
        "VL2_model.fit(x=[input_train01,input_train02],y=output_train,steps_per_epoch=1000,epochs=20,validation_data=[[input_test01,input_test02],output_test],validation_steps=300)\n",
        "\n",
        "target_dir = '/content/drive/My Drive/modelo/'\n",
        "if not os.path.exists(target_dir):\n",
        "    os.mkdir(target_dir)\n",
        "    VL2_model.save('/content/drive/My Drive/modelo/modelo.h5')\n",
        "    VL2_model.save_weights('/content/drive/My Drive/modelo/pesos.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}